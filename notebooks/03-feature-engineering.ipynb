{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bfbfdd95",
      "metadata": {},
      "source": [
        "# 03 — Feature Engineering\n",
        "\n",
        "**Purpose:** Construct modeling‑ready features from preprocessed country‑year data: lag/rolling statistics, nonlinear transforms, and interactions. Save a single feature matrix for modeling.\n",
        "\n",
        "**Inputs:** `./data/processed/countries_preprocessed.csv`  \n",
        "**Outputs:** `./data/processed/countries_features.csv`\n",
        "\n",
        "**Key decisions/assumptions**\n",
        "- Countries only (aggregates removed upstream).\n",
        "- Time‑safe features (lag/roll) computed within country groups.\n",
        "- Target (`cereal_yield`) is not imputed here; any imputation occurs in the modeling pipeline.\n",
        "- Current‑year nonlinearities (log/square) and interactions are included to enrich scenario heterogeneity.\n",
        "- Lags/rolls for `cereal_yield`, `temp_anomaly`, `precipitation` (and derived lag1 squares + lag1 interaction)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "789d8a18",
      "metadata": {},
      "source": [
        "## 1) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f4796f49",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading: /Users/golibsanaev/Library/CloudStorage/Dropbox/GitHub_gsanaev/crop-yield-prediction-climate-change/data/processed/countries_preprocessed.csv\n",
            "Shape in: (14040, 17)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "DATA_IN  = Path(\"../data/processed/countries_preprocessed.csv\")\n",
        "DATA_OUT = Path(\"../data/processed/countries_features.csv\")\n",
        "\n",
        "print(\"Reading:\", DATA_IN.resolve())\n",
        "df = pd.read_csv(DATA_IN)\n",
        "print(\"Shape in:\", df.shape)\n",
        "\n",
        "# Ensure 'year' is numeric (Int64) for safe sorting\n",
        "if \"year\" in df.columns:\n",
        "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b62edc53",
      "metadata": {},
      "source": [
        "## 2) Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "42f86f34",
      "metadata": {},
      "outputs": [],
      "source": [
        "def group_key(frame: pd.DataFrame) -> str:\n",
        "    if \"Country Name\" in frame.columns: \n",
        "        return \"Country Name\"\n",
        "    if \"Country Code\" in frame.columns: \n",
        "        return \"Country Code\"\n",
        "    raise KeyError(\"Expected 'Country Name' or 'Country Code' in columns.\")\n",
        "\n",
        "def add_group_lag(frame: pd.DataFrame, col: str, lag: int, new_name: str) -> None:\n",
        "    gk = group_key(frame)\n",
        "    frame[new_name] = (\n",
        "        frame.sort_values([gk, \"year\"])\n",
        "             .groupby(gk, group_keys=False)[col]\n",
        "             .shift(lag)\n",
        "    )\n",
        "\n",
        "def add_group_roll_mean(frame: pd.DataFrame, col: str, window: int, new_name: str) -> None:\n",
        "    gk = group_key(frame)\n",
        "    frame[new_name] = (\n",
        "        frame.sort_values([gk, \"year\"])\n",
        "             .groupby(gk, group_keys=False)[col]\n",
        "             .rolling(window, min_periods=1)\n",
        "             .mean()\n",
        "             .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "def safe_log1p(series: pd.Series) -> pd.Series:\n",
        "    vals = pd.to_numeric(series, errors=\"coerce\")\n",
        "    vals = vals.clip(lower=0)\n",
        "    return np.log1p(vals)\n",
        "\n",
        "def safe_square(series: pd.Series) -> pd.Series:\n",
        "    vals = pd.to_numeric(series, errors=\"coerce\")\n",
        "    return vals ** 2\n",
        "\n",
        "def safe_interaction(a: pd.Series, b: pd.Series) -> pd.Series:\n",
        "    a = pd.to_numeric(a, errors=\"coerce\")\n",
        "    b = pd.to_numeric(b, errors=\"coerce\")\n",
        "    return a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16036cd9",
      "metadata": {},
      "source": [
        "## 3) Nonlinear transforms (current year)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0b0f6bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added nonlinear cols: ['log_fertilizer_use', 'fertilizer_use_sq', 'temp_anomaly_sq', 'precipitation_sq', 'log_gdp_per_capita']\n"
          ]
        }
      ],
      "source": [
        "added_cols = []\n",
        "\n",
        "# Log/square on key drivers (current-year)\n",
        "if \"fertilizer_use\" in df.columns:\n",
        "    df[\"log_fertilizer_use\"] = safe_log1p(df[\"fertilizer_use\"]); added_cols.append(\"log_fertilizer_use\")\n",
        "    df[\"fertilizer_use_sq\"] = safe_square(df[\"fertilizer_use\"]); added_cols.append(\"fertilizer_use_sq\")\n",
        "\n",
        "if \"temp_anomaly\" in df.columns:\n",
        "    df[\"temp_anomaly_sq\"] = safe_square(df[\"temp_anomaly\"]); added_cols.append(\"temp_anomaly_sq\")\n",
        "\n",
        "if \"precipitation\" in df.columns:\n",
        "    df[\"precipitation_sq\"] = safe_square(df[\"precipitation\"]); added_cols.append(\"precipitation_sq\")\n",
        "\n",
        "# Optional macro logs (kept lightweight)\n",
        "if \"gdp_per_capita\" in df.columns:\n",
        "    df[\"log_gdp_per_capita\"] = safe_log1p(df[\"gdp_per_capita\"]); added_cols.append(\"log_gdp_per_capita\")\n",
        "\n",
        "print(\"Added nonlinear cols:\", added_cols if added_cols else \"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470d0867",
      "metadata": {},
      "source": [
        "## 4) Lag/rolling features (time‑safe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e0736112",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added lag cols: ['cereal_yield_lag1', 'temp_anomaly_lag1', 'precipitation_lag1', 'temp_anomaly_lag1_sq', 'precipitation_lag1_sq']\n",
            "Added roll cols: ['cereal_yield_roll3', 'temp_anomaly_roll3', 'precipitation_roll3']\n"
          ]
        }
      ],
      "source": [
        "lag_added, roll_added = [], []\n",
        "\n",
        "# Lags: 1-year for key series\n",
        "for base in [\"cereal_yield\", \"temp_anomaly\", \"precipitation\"]:\n",
        "    if base in df.columns:\n",
        "        newc = f\"{base}_lag1\"\n",
        "        add_group_lag(df, base, lag=1, new_name=newc)\n",
        "        lag_added.append(newc)\n",
        "\n",
        "# Roll: 3-year rolling mean for key series\n",
        "for base in [\"cereal_yield\", \"temp_anomaly\", \"precipitation\"]:\n",
        "    if base in df.columns:\n",
        "        newc = f\"{base}_roll3\"\n",
        "        add_group_roll_mean(df, base, window=3, new_name=newc)\n",
        "        roll_added.append(newc)\n",
        "\n",
        "# Lag1 squares (used later in modeling & scenarios)\n",
        "for base in [\"temp_anomaly\", \"precipitation\"]:\n",
        "    lagc = f\"{base}_lag1\"\n",
        "    if lagc in df.columns:\n",
        "        sqc = f\"{lagc}_sq\"\n",
        "        df[sqc] = safe_square(df[lagc])\n",
        "        lag_added.append(sqc)\n",
        "\n",
        "print(\"Added lag cols:\", lag_added if lag_added else \"none\")\n",
        "print(\"Added roll cols:\", roll_added if roll_added else \"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23609d5d",
      "metadata": {},
      "source": [
        "## 5) Interactions (current‑year and lag‑aware)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "683942ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added interaction cols: ['tempXprecip', 'tempXfertilizer', 'precipXfertilizer', 'tempXprecip_lag1']\n"
          ]
        }
      ],
      "source": [
        "inter_added = []\n",
        "\n",
        "# Current-year interactions\n",
        "if set([\"temp_anomaly\", \"precipitation\"]).issubset(df.columns):\n",
        "    df[\"tempXprecip\"] = safe_interaction(df[\"temp_anomaly\"], df[\"precipitation\"]); inter_added.append(\"tempXprecip\")\n",
        "\n",
        "if set([\"temp_anomaly\", \"fertilizer_use\"]).issubset(df.columns):\n",
        "    df[\"tempXfertilizer\"] = safe_interaction(df[\"temp_anomaly\"], df[\"fertilizer_use\"]); inter_added.append(\"tempXfertilizer\")\n",
        "\n",
        "if set([\"precipitation\", \"fertilizer_use\"]).issubset(df.columns):\n",
        "    df[\"precipXfertilizer\"] = safe_interaction(df[\"precipitation\"], df[\"fertilizer_use\"]); inter_added.append(\"precipXfertilizer\")\n",
        "\n",
        "# Lag1 interaction (used by modeling/scenarios)\n",
        "if set([\"temp_anomaly_lag1\", \"precipitation_lag1\"]).issubset(df.columns):\n",
        "    df[\"tempXprecip_lag1\"] = safe_interaction(df[\"temp_anomaly_lag1\"], df[\"precipitation_lag1\"]); inter_added.append(\"tempXprecip_lag1\")\n",
        "\n",
        "print(\"Added interaction cols:\", inter_added if inter_added else \"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3a0ac17",
      "metadata": {},
      "source": [
        "## 6) Simple ratios (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5528c062",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added ratios: ['fertilizer_per_gdp']\n"
          ]
        }
      ],
      "source": [
        "ratio_added = []\n",
        "if set([\"fertilizer_use\", \"gdp_per_capita\"]).issubset(df.columns):\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        ratio = pd.to_numeric(df[\"fertilizer_use\"], errors=\"coerce\") / pd.to_numeric(df[\"gdp_per_capita\"], errors=\"coerce\")\n",
        "        ratio = ratio.replace([np.inf, -np.inf], np.nan)\n",
        "        df[\"fertilizer_per_gdp\"] = ratio\n",
        "        ratio_added.append(\"fertilizer_per_gdp\")\n",
        "\n",
        "print(\"Added ratios:\", ratio_added if ratio_added else \"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "363eb33f",
      "metadata": {},
      "source": [
        "## 7) Sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "73162036",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top missingness (%):\n",
            "precipXfertilizer        34.1\n",
            "fertilizer_per_gdp       34.1\n",
            "fertilizer_use_sq        30.0\n",
            "log_fertilizer_use       30.0\n",
            "tempXfertilizer          30.0\n",
            "fertilizer_use           30.0\n",
            "cereal_yield             28.2\n",
            "log_cereal_yield         28.2\n",
            "cereal_yield_lag1        28.2\n",
            "precipitation            26.9\n",
            "precipitation_sq         26.9\n",
            "tempXprecip              26.9\n",
            "precipitation_lag1_sq    26.9\n",
            "precipitation_lag1       26.9\n",
            "tempXprecip_lag1         26.9\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Leakage guardrail: ensure we're not introducing obviously future-labelled cols\n",
        "bad_cols = [c for c in df.columns if c.endswith(\"_future\") or c.startswith(\"future_\")]\n",
        "assert not bad_cols, f\"Found future-labelled columns: {bad_cols}\"\n",
        "\n",
        "# Quick missingness snapshot (top 15)\n",
        "mis = df.isna().mean().sort_values(ascending=False) * 100\n",
        "print(\"Top missingness (%):\")\n",
        "print(mis.head(15).round(1))\n",
        "\n",
        "# Minimal column presence check for target and year\n",
        "assert \"cereal_yield\" in df.columns, \"Target 'cereal_yield' missing after transforms.\"\n",
        "assert \"year\" in df.columns, \"'year' missing; required for time-safe features.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ee2821",
      "metadata": {},
      "source": [
        "## 8) Save features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5a214729",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/golibsanaev/Library/CloudStorage/Dropbox/GitHub_gsanaev/crop-yield-prediction-climate-change/data/processed/countries_features.csv\n",
            "Final shape: (14040, 33)\n"
          ]
        }
      ],
      "source": [
        "df.to_csv(DATA_OUT, index=False)\n",
        "print(\"Saved:\", DATA_OUT.resolve())\n",
        "print(\"Final shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8931566e",
      "metadata": {},
      "source": [
        "## 9) Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c500512",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.12.11\n",
            "Platform: macOS-15.6.1-arm64-arm-64bit\n",
            "NumPy: 2.3.3\n",
            "Pandas: 2.3.3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import platform\n",
        "import numpy\n",
        "import pandas\n",
        "\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "print(\"Pandas:\", pandas.__version__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "crop (3.12.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
