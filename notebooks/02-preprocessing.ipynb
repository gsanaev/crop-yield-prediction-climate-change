{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90806319",
   "metadata": {},
   "source": [
    "# 02 — Preprocessing (Clean & Harmonize)\n",
    "\n",
    "**Purpose:** Load the country-only panel, fix types and column hygiene, add log transforms for skewed variables, and (optionally) standardize **feature** columns. No target imputation or time-window filtering is done here.\n",
    "\n",
    "**Inputs:** `../data/processed/countries_only.csv`\n",
    "\n",
    "**Outputs (CSV only):** `../data/processed/countries_preprocessed.csv`\n",
    "\n",
    "**Key decisions/assumptions:**\n",
    "- Countries only; aggregates remain excluded (as in 01).\n",
    "- No target imputation; `cereal_yield` may remain missing (handled in modeling).\n",
    "- Do not scale/transform `year`.\n",
    "- Create `log_*` companions for selected skewed variables.\n",
    "- If scaling is enabled, standardize **features only** (exclude `year`, `cereal_yield`, and identifiers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19856d",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Define stable paths and display options. A local fallback (`/mnt/data`) supports hosted or containerized runs. This cell establishes a consistent entry point across environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91464d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Consistent with 01 (use ../)\n",
    "DATA_PATH = Path(\"../data/processed/countries_only.csv\")\n",
    "FALLBACK  = Path(\"/mnt/data/countries_only.csv\")  # optional\n",
    "OUT_PATH  = Path(\"../data/processed/countries_preprocessed.csv\")\n",
    "\n",
    "if not DATA_PATH.exists() and FALLBACK.exists():\n",
    "    DATA_PATH = FALLBACK\n",
    "print(\"Using data from:\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f9a7e",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "Read the country-only panel produced in 01. The initial shape and a short preview help confirm that the upstream split executed as expected and that columns are present for downstream steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8823f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b711d",
   "metadata": {},
   "source": [
    "## 3. Data types and ordering\n",
    "Cast `year` to a nullable integer (`Int64`) to preserve missing years without coercing to floats. Force identifiers (`Country Name`, `Country Code`) to string to avoid unintended numeric interpretation. Sort by `(Country Name, year)` to make joins, comparisons, and diffs deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year as nullable integer\n",
    "if \"year\" in df.columns:\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# identifiers as strings\n",
    "for col in [\"Country Code\", \"Country Name\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "# sort\n",
    "order_cols = [c for c in [\"Country Name\", \"year\"] if c in df.columns]\n",
    "if order_cols:\n",
    "    df = df.sort_values(order_cols).reset_index(drop=True)\n",
    "\n",
    "df.dtypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87467bed",
   "metadata": {},
   "source": [
    "## 4. Log transforms\n",
    "Create `log_*` companions for right-skewed variables (e.g., `cereal_yield`, `fertilizer_use`, `gdp_per_capita`) using `log1p`. Negative inputs are clipped to zero to prevent invalid logs. Original columns are retained to keep both raw and transformed representations available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_VARS = [c for c in [\"cereal_yield\", \"fertilizer_use\", \"gdp_per_capita\"] if c in df.columns]\n",
    "\n",
    "for col in LOG_VARS:\n",
    "    vals = pd.to_numeric(df[col], errors=\"coerce\").clip(lower=0)\n",
    "    df[f\"log_{col}\"] = np.log1p(vals)\n",
    "\n",
    "print(\"Created:\", [f\"log_{c}\" for c in LOG_VARS])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf7530",
   "metadata": {},
   "source": [
    "## 5. Optional standardization\n",
    "Leave scaling disabled by default. When enabled, standardize only numeric **feature** columns and exclude `year`, the **target** (`cereal_yield`), and identifiers. Standardization improves feature comparability for scale-sensitive models (e.g., linear, distance-based), while tree-based models typically do not require it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_SCALING = False  # set True to scale numeric features\n",
    "\n",
    "if ENABLE_SCALING:\n",
    "    numeric_cols = df.select_dtypes(include=[np.number, \"Float64\", \"Int64\"]).columns.tolist()\n",
    "    exclude = {\"year\", \"cereal_yield\"} | set([c for c in [\"Country Code\", \"Country Name\"] if c in df.columns])\n",
    "    feature_cols = [c for c in numeric_cols if c not in exclude]\n",
    "    scaler = StandardScaler()\n",
    "    df.loc[:, feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "    print(\"Scaled columns:\", feature_cols)\n",
    "else:\n",
    "    print(\"Scaling disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d132b1",
   "metadata": {},
   "source": [
    "## 6. Save output\n",
    "Write a single artifact: `../data/processed/countries_preprocessed.csv`. This file serves as the canonical input to feature engineering in 03 and keeps the pipeline’s I/O contract simple and auditable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ffbb03",
   "metadata": {},
   "source": [
    "## 7. Sanity checks\n",
    "Report final shape, list of columns, and top missing-value rates. These quick summaries surface schema drift and unexpected sparsity before feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79022fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final shape:\", df.shape)\n",
    "print(\"Columns (first 20):\", list(df.columns)[:20], \"...\")\n",
    "df.isna().mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d0574",
   "metadata": {},
   "source": [
    "## 8. Environment\n",
    "Print key package versions (Python, NumPy, pandas, scikit-learn). Capturing versions supports reproducibility and simplifies debugging across machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform, numpy, pandas, sklearn\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"NumPy:\", numpy.__version__)\n",
    "print(\"Pandas:\", pandas.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crop (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
